{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from math import exp\n",
    "from math import log\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print (\"Reading data...\")\n",
    "data = list(parseData(\"beer_50000.json\"))\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is done!\n"
     ]
    }
   ],
   "source": [
    "# train a predictor that estimates whether a beer is an ‘American IPA’ using 'beer/ABV' and 'review/taste'\n",
    "data2 = [d for d in data if 'beer/ABV' in d and 'review/taste' in d and 'beer/style' in d]\n",
    "\n",
    "X = [[d['beer/ABV'],d['review/taste']] for d in data2]\n",
    "y = [int(\"American IPA\" in d['beer/style']) for d in data2]\n",
    "\n",
    "halfway = int(len(data2)/2)\n",
    "\n",
    "X_train = X[:halfway]\n",
    "y_train = y[:halfway]\n",
    "\n",
    "X_test = X[halfway:]\n",
    "y_test = y[halfway:]\n",
    "\n",
    "# Create a support vector classifier object, with regularization parameter C = 1000\n",
    "clf = svm.SVC(C=1000, kernel='sigmoid')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"training is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set: 0.85312\n",
      "accuracy on test set: 0.87344\n"
     ]
    }
   ],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_train)):\n",
    "  if train_predictions[i] == y_train[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on training set: \" + str(num_correct/len(X_train)))\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_test)):\n",
    "  if test_predictions[i] == y_test[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on test set: \" + str(num_correct/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is done!\n"
     ]
    }
   ],
   "source": [
    "# finding better features for predicting 'American IPA'\n",
    "data3 = [d for d in data if 'beer/ABV' in d and 'review/palate' in d and 'beer/style' in d]\n",
    "\n",
    "X = [[1,d['beer/ABV'],d['review/palate']] for d in data3]\n",
    "y = [int(\"American IPA\" in d['beer/style']) for d in data3]\n",
    "\n",
    "halfway = int(len(data2)/2)\n",
    "\n",
    "X_train = X[:halfway]\n",
    "y_train = y[:halfway]\n",
    "\n",
    "X_test = X[halfway:]\n",
    "y_test = y[halfway:]\n",
    "\n",
    "# Create a support vector classifier object, with regularization parameter C = 1000\n",
    "clf = svm.SVC(C=1000, kernel='sigmoid')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"training is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set: 0.83884\n",
      "accuracy on test set: 0.8758\n"
     ]
    }
   ],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_train)):\n",
    "  if train_predictions[i] == y_train[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on training set: \" + str(num_correct/len(X_train)))\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_test)):\n",
    "  if test_predictions[i] == y_test[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on test set: \" + str(num_correct/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C = 0.1\n",
      "accuracy on training set: 0.91352\n",
      "accuracy on test set: 0.92184\n"
     ]
    }
   ],
   "source": [
    "# testing different regularization constants and their accuracy results\n",
    "clf = svm.SVC(C=0.1, kernel='sigmoid')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print (\"Using C = 0.1\")\n",
    "\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_train)):\n",
    "  if train_predictions[i] == y_train[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on training set: \" + str(num_correct/len(X_train)))\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_test)):\n",
    "  if test_predictions[i] == y_test[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on test set: \" + str(num_correct/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C = 10\n",
      "accuracy on training set: 0.90752\n",
      "accuracy on test set: 0.92004\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=10, kernel='sigmoid')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print (\"Using C = 10\")\n",
    "\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_train)):\n",
    "  if train_predictions[i] == y_train[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on training set: \" + str(num_correct/len(X_train)))\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_test)):\n",
    "  if test_predictions[i] == y_test[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on test set: \" + str(num_correct/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C = 100000\n",
      "accuracy on training set: 0.83108\n",
      "accuracy on test set: 0.86116\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C=10000, kernel='sigmoid')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print (\"Using C = 100000\")\n",
    "\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_train)):\n",
    "  if train_predictions[i] == y_train[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on training set: \" + str(num_correct/len(X_train)))\n",
    "\n",
    "num_correct = 0\n",
    "for i in range (0, len(X_test)):\n",
    "  if test_predictions[i] == y_test[i]:\n",
    "    num_correct += 1\n",
    "print (\"accuracy on test set: \" + str(num_correct/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0.0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    # Fill in code for the derivative\n",
    "    for j in range (len(theta)):\n",
    "      dl[j] -= (sigmoid(inner(theta,X[i])) - y[i])*X[i][j]\n",
    "  # Negate the return value since we're doing gradient *ascent*\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "\n",
    "X = [[1,d['beer/ABV'],d['review/taste']] for d in data2]\n",
    "y = [int(\"American IPA\" in d['beer/style']) for d in data2]\n",
    "\n",
    "halfway = int(len(data2)/2)\n",
    "\n",
    "X_train = X[:halfway]\n",
    "X_test = X[halfway:]\n",
    "\n",
    "# Use a library function to run gradient descent (or you can implement yourself!)\n",
    "theta,l,info = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, args = (X_train, y_train, 1.0))\n",
    "print (\"Final log likelihood =\", -l)\n",
    "\n",
    "print (theta)\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for i in range (0,len(X)):\n",
    "  if abs(sigmoid(inner(theta,X[i])) - y[i]) < 0.5:\n",
    "    num_correct += 1\n",
    "\n",
    "print (\"Accuracy = \" + str(num_correct/len(X))) # Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.31049343 -0.21663721  0.43895716]]\n",
      "Accuracy = 0.91752\n"
     ]
    }
   ],
   "source": [
    "# comparing with built in logistic regression function\n",
    "logistic = LogisticRegression()\n",
    "test = logistic.fit(X,y)\n",
    "print (test.coef_)\n",
    "\n",
    "theta = test.coef_[0]\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for i in range (0,len(X)):\n",
    "  if abs(sigmoid(inner(theta,X[i])) - y[i]) < 0.5:\n",
    "    num_correct += 1\n",
    "\n",
    "print (\"Accuracy = \" + str(num_correct/len(X))) # Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
