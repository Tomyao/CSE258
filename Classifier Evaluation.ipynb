{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import scipy.optimize\n",
    "import random\n",
    "import string\n",
    "from math import exp\n",
    "from math import log\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print (\"Reading data...\")\n",
    "data = list(parseData(\"beer_50000.json\"))\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam, X_train, y_train):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, X_set, y_set):\n",
    "  scores = [inner(theta,x) for x in X_set]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "  correct = [(a==b) for (a,b) in zip(predictions,y_set)]\n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "Accuracy on validation set: 0.90027601104\n",
      "Accuracy on test set: 0.577813774898\n"
     ]
    }
   ],
   "source": [
    "# Problem 1\n",
    "\n",
    "# Splitting into thirds\n",
    "one_third = int(len(X)/3)\n",
    "two_third = 2*one_third\n",
    "\n",
    "X_training_set = X[:one_third]\n",
    "y_training_set = y[:one_third]\n",
    "\n",
    "X_validation_set = X[one_third:two_third]\n",
    "y_validation_set = y[one_third:two_third]\n",
    "\n",
    "X_test_set = X[two_third:]\n",
    "y_test_set = y[two_third:]\n",
    "\n",
    "# define lambda\n",
    "lam = 1.0\n",
    "\n",
    "# train on training set\n",
    "theta = train(lam, X_training_set, y_training_set)\n",
    "print (\"Training done!\")\n",
    "\n",
    "# get accuracy on validation set\n",
    "acc = performance(theta, X_validation_set, y_validation_set)\n",
    "print (\"Accuracy on validation set: \" + str(acc))\n",
    "\n",
    "# get accuracy on test set\n",
    "acc = performance(theta, X_test_set, y_test_set)\n",
    "print (\"Accuracy on test set: \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Problem 2\n",
    "\n",
    "# Define the words\n",
    "words = [\"lactic\", \"tart\", \"sour\", \"citric\", \"sweet\", \"acid\", \"hop\", \"fruit\", \"salt\", \"spicy\"]\n",
    "\n",
    "# Getting the word counts\n",
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  counts = [0]*len(words)\n",
    "  mystring = datum['review/text']\n",
    "  mystring = mystring.translate(str.maketrans('','',string.punctuation))\n",
    "  mywords = mystring.split()\n",
    "  for i in range (0, len(mywords)):\n",
    "    for j in range (0, len(words)):\n",
    "      if mywords[i].lower() == words[j]:\n",
    "        counts[j] += 1\n",
    "  feat = feat + counts\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "# Splitting into thirds\n",
    "one_third = int(len(X)/3)\n",
    "two_third = 2*one_third\n",
    "\n",
    "X_training_set = X[:one_third]\n",
    "y_training_set = y[:one_third]\n",
    "\n",
    "X_validation_set = X[one_third:two_third]\n",
    "y_validation_set = y[one_third:two_third]\n",
    "\n",
    "X_test_set = X[two_third:]\n",
    "y_test_set = y[two_third:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done!\n",
      "True positives in test set: 5834\n",
      "True negatives in test set: 206\n",
      "False positives in test set: 10549\n",
      "False negatives in test set: 79\n",
      "Balanced Error Rate on test set: 0.49710325522021903\n"
     ]
    }
   ],
   "source": [
    "# Problem 3\n",
    "\n",
    "def error_statistics(theta, X_set, y_set):\n",
    "  acc = [0,0,0,0,0]\n",
    "  scores = [inner(theta,x) for x in X_set]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "  # True positives\n",
    "  for (a,b) in zip(predictions,y_set):\n",
    "    if a == True and b == True:\n",
    "      acc[0] += 1\n",
    "  # True negatives\n",
    "  for (a,b) in zip(predictions,y_set):\n",
    "    if a == False and b == False:\n",
    "      acc[1] += 1\n",
    "  # False positives\n",
    "  for (a,b) in zip(predictions,y_set):\n",
    "    if a == True and b == False:\n",
    "      acc[2] += 1\n",
    "  # False negatives\n",
    "  for (a,b) in zip(predictions,y_set):\n",
    "    if a == False and b == True:\n",
    "      acc[3] += 1\n",
    "  # Balanced Error Rate\n",
    "  acc[4] = 1 - 0.5*(acc[0]/(acc[0]+acc[3]) + acc[1]/(acc[1]+acc[2]))\n",
    "  return acc\n",
    "\n",
    "# define lambda\n",
    "lam = 1.0\n",
    "\n",
    "# train on training set\n",
    "theta = train(lam, X_training_set, y_training_set)\n",
    "print (\"Training done!\")\n",
    "\n",
    "# evaluate on test set\n",
    "acc = error_statistics(theta, X_test_set, y_test_set)\n",
    "print (\"True positives in test set: \" + str(acc[0]))\n",
    "print (\"True negatives in test set: \" + str(acc[1]))\n",
    "print (\"False positives in test set: \" + str(acc[2]))\n",
    "print (\"False negatives in test set: \" + str(acc[3]))\n",
    "print (\"Balanced Error Rate on test set: \" + str(acc[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio: 1.2773981962284777\n",
      "Training done!\n",
      "Balanced Error Rate on training set: 0.4342908816345251\n",
      "Balanced Error Rate on validation set: 0.4108055686954606\n",
      "Balanced Error Rate on test set: 0.4434130314950322\n"
     ]
    }
   ],
   "source": [
    "# Problem 4\n",
    "\n",
    "# Redefine functions to better account for class imbalance\n",
    "\n",
    "# A ratio of 1 means no imbalance\n",
    "ratio = 1\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "      loglikelihood -= (log(1 + exp(-logit)) + logit)*(ratio - 1)\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "        dl[k] -= (X[i][k]*sigmoid(logit))*(ratio - 1)\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "temp1 = (sum(y_training_set))\n",
    "temp2 = (len(y_training_set) - sum(y_training_set))\n",
    "print (\"Ratio: \" + str(temp1/temp2))\n",
    "ratio = temp1/temp2\n",
    "\n",
    "# define lambda\n",
    "lam = 1.0\n",
    "\n",
    "# train on training set\n",
    "theta = train(lam, X_training_set, y_training_set)\n",
    "print (\"Training done!\")\n",
    "\n",
    "# evaluate on training set\n",
    "acc = error_statistics(theta, X_training_set, y_training_set)\n",
    "print (\"Balanced Error Rate on training set: \" + str(acc[4]))\n",
    "\n",
    "# evaluate on validation set\n",
    "acc = error_statistics(theta, X_validation_set, y_validation_set)\n",
    "print (\"Balanced Error Rate on validation set: \" + str(acc[4]))\n",
    "\n",
    "# evaluate on test set\n",
    "acc = error_statistics(theta, X_test_set, y_test_set)\n",
    "print (\"Balanced Error Rate on test set: \" + str(acc[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0\n",
      "Training done!\n",
      "Balanced Error Rate on training set: 0.4343295317096092\n",
      "Balanced Error Rate on validation set: 0.4110884452355663\n",
      "Balanced Error Rate on test set: 0.44343425980765727\n",
      "Lambda: 0.01\n",
      "Training done!\n",
      "Balanced Error Rate on training set: 0.4342908816345251\n",
      "Balanced Error Rate on validation set: 0.4108055686954606\n",
      "Balanced Error Rate on test set: 0.4434130314950322\n",
      "Lambda: 0.1\n",
      "Training done!\n",
      "Balanced Error Rate on training set: 0.4342908816345251\n",
      "Balanced Error Rate on validation set: 0.4108055686954606\n",
      "Balanced Error Rate on test set: 0.4434130314950322\n",
      "Lambda: 1\n",
      "Training done!\n",
      "Balanced Error Rate on training set: 0.4342908816345251\n",
      "Balanced Error Rate on validation set: 0.4108055686954606\n",
      "Balanced Error Rate on test set: 0.4434130314950322\n",
      "Lambda: 100\n",
      "Training done!\n",
      "Balanced Error Rate on training set: 0.4342967434651259\n",
      "Balanced Error Rate on validation set: 0.4106169843353902\n",
      "Balanced Error Rate on test set: 0.44348478319170515\n"
     ]
    }
   ],
   "source": [
    "# Problem 5\n",
    "\n",
    "def pipeline(training_set_X, training_set_y, validation_set_X, validation_set_y, test_set_X, test_set_y, lam):\n",
    "    print (\"Lambda: \" + str(lam))\n",
    "    \n",
    "    theta = train(lam, training_set_X, training_set_y)\n",
    "    print (\"Training done!\")\n",
    "    \n",
    "    # evaluate on training set\n",
    "    acc = error_statistics(theta, training_set_X, training_set_y)\n",
    "    print (\"Balanced Error Rate on training set: \" + str(acc[4]))\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc = error_statistics(theta, validation_set_X, validation_set_y)\n",
    "    print (\"Balanced Error Rate on validation set: \" + str(acc[4]))\n",
    "\n",
    "    # evaluate on test set\n",
    "    acc = error_statistics(theta, test_set_X, test_set_y)\n",
    "    print (\"Balanced Error Rate on test set: \" + str(acc[4]))\n",
    "    \n",
    "lambda_values = [0, 0.01, 0.1, 1, 100]\n",
    "\n",
    "for i in range (0,len(lambda_values)):\n",
    "    pipeline(X_training_set, y_training_set, X_validation_set, y_validation_set, X_test_set, y_test_set, lambda_values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
